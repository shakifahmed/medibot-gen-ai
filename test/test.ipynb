{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc9b449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_together import ChatTogether\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "from langchain.retrievers import MultiQueryRetriever\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f7ec2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'\\xef\\xbb\\xbf%P'\n",
      "EOF marker seems truncated\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      "PdfReadError(\"Invalid Elementary Object starting with b'e' @27066: b' R/MediaBox[-2e-05 0 560.159973 722.880005]/Annots 21 0 R/CropBox[-2e-05 1.44 56'\")\n",
      "PdfReadError(\"Invalid Elementary Object starting with b'P' @33017702: b'5 0 obj<</Universal PDF(The process that creates this PDF constitutes a trade se'\")\n",
      "PdfReadError(\"Invalid Elementary Object starting with b'P' @33017702: b'5 0 obj<</Universal PDF(The process that creates this PDF constitutes a trade se'\")\n",
      "PdfReadError(\"Invalid Elementary Object starting with b'e' @27066: b' R/MediaBox[-2e-05 0 560.159973 722.880005]/Annots 21 0 R/CropBox[-2e-05 1.44 56'\")\n"
     ]
    }
   ],
   "source": [
    "dir_loader = DirectoryLoader(\n",
    "    path='D:\\LangChain\\Langchain_Models\\MediBot\\data',\n",
    "    glob='*.pdf',\n",
    "    loader_cls=PyPDFLoader\n",
    ")\n",
    "docs = dir_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f961f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = GoogleGenerativeAIEmbeddings(model='models/text-embedding-004')\n",
    "query_result = embedding.embed_query('hi')\n",
    "embedding_dimension = len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5f6d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7017afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing index stats: {'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 46900}},\n",
      " 'total_vector_count': 46900,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "index_name = \"medibot\"\n",
    "\n",
    "try:\n",
    "    index_created = False\n",
    "\n",
    "    # 1. Create index if not exists\n",
    "    if not pc.has_index(index_name):\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=embedding_dimension,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "        )\n",
    "        index_created = True\n",
    "        print(\"Created new database index\")\n",
    "\n",
    "    # 2. Initialize index object\n",
    "    index = pc.Index(index_name)\n",
    "\n",
    "    # 3. If newly created, insert documents\n",
    "    if index_created:\n",
    "        try:\n",
    "            vector_store = PineconeVectorStore.from_documents(\n",
    "                documents=chunks,\n",
    "                index_name=index_name,\n",
    "                embedding=embedding\n",
    "            )\n",
    "            print(\"Data inserted using from_documents()\")\n",
    "        except Exception as e:\n",
    "            print(f\"from_documents failed: {e}\")\n",
    "            print(\"Trying batch insert...\")\n",
    "\n",
    "            vector_store = PineconeVectorStore(index_name=index_name, embedding=embedding)\n",
    "            batch_size = 200\n",
    "            for i in range(0, len(chunks), batch_size):\n",
    "                batch = chunks[i:i + batch_size]\n",
    "                vector_store.add_documents(documents=batch)\n",
    "            print(\"Data inserted using batch upload\")\n",
    "    else:\n",
    "        # 4. Load existing vector store only\n",
    "        vector_store = PineconeVectorStore.from_existing_index(\n",
    "            index_name=index_name,\n",
    "            embedding=embedding\n",
    "        )\n",
    "        stats = index.describe_index_stats()\n",
    "        print(\"Existing index stats:\", stats)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to Pinecone index: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0461f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model='models/gemini-2.5-pro')\n",
    "compressor = LLMChainExtractor.from_llm(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e64151cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mq_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vector_store.as_retriever(search_kwargs={'k':2}),\n",
    "    llm=llm\n",
    ")\n",
    "retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever= mq_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd3e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"india vs england test score today\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbd7be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\\n\".join(i.page_content for i in retriever.invoke(query) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e83eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=(\n",
    "            \"You are a helpful and knowledgeable medical assistant. \"\n",
    "            \"Answer the user's following medical question in simple and accurate terms. \"\n",
    "            \"It would be preferred if you add some bullet points when answering the question.\\n\\n\"\n",
    "            \"Use the following retrieved context to answer the question:\\n\"\n",
    "            f\"{context}\\n\\n\"\n",
    "            \"If the answer is not in the context, say you don't know.\"\n",
    "        )\n",
    "    ),\n",
    "    HumanMessage(content=query)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "478e3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(messages)\n",
    "messages.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "099f1d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, I don't know the answer to your question.\\n\\nAs a medical assistant, my purpose is to provide information on health-related topics. I do not have access to live sports scores.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--9728ea1b-5d9f-4fe3-a644-6a2234758d52-0', usage_metadata={'input_tokens': 73, 'output_tokens': 44, 'total_tokens': 799, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't know the answer to your question.\\n\\nAs a medical assistant, my purpose is to provide information on health-related topics. I do not have access to live sports scores.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
